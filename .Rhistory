df_H_PSD <- mutate(.data = df_H_PSD,ID_Week = if_else(Date >= RefDate,ID_Week+1,ID_Week))
}
df <- df_H_PSD %>%
left_join(ZZZ_LoadSteps, by=c('Key'='Key','Date'='Date')) %>%
left_join(df_W_PSD,by=c('ID_Week'='ID_Week','SubMkt'='SubMkt','LoadStep'='LoadStep')) %>%
mutate(Year = str_sub(Date,1,4)) %>%
rename(timestamp = Key) %>% mutate(`Year/Month` = paste0(Year,'/',str_sub(Date,6,7))) %>%
mutate(`Year/Month/Day` = paste0(day(`Year/Month`)))
df <- df_H_PSD %>%
left_join(ZZZ_LoadSteps, by=c('Key'='Key','Date'='Date')) %>%
left_join(df_W_PSD,by=c('ID_Week'='ID_Week','SubMkt'='SubMkt','LoadStep'='LoadStep')) %>%
mutate(Year = str_sub(Date,1,4)) %>%
rename(timestamp = Key) %>% mutate(`Year/Month` = paste0(Year,'/',str_sub(Date,6,7))) %>%
mutate(`Year/Month/Day` = paste0(`Year/Month`,'/',day(Date)))
rm(list = ls()); gc();
#### Libraries, Options and Parameters.####
options(java.parameters = "-Xmx48g",scipen=999)
#Calls for libraries (or installs them if missing).
#It is worth noting that this code has to be executed on RStudio IDE due to
#the rstudioapi package. It offers the rstudio::getActiveDocumentContext() that
#allows relative paths.
vec.pkg <- c('MASS',"rstudioapi","lubridate","tidyverse","tictoc",'readxl')
vec.newpkg <- vec.pkg[!(vec.pkg %in% installed.packages()[,"Package"])]
if(length(vec.newpkg)) install.packages(vec.newpkg)
lapply(vec.pkg, require, character.only = TRUE)
rm(vec.pkg,vec.newpkg)
#Sets the current folder of the script as the working directory.
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
ZZZ_VLookUp_Holidays <- readxl::read_excel('Other_Data/PSD_Holidays.xlsx') %>%
mutate(Date = ymd(Date))
#### Boundaries (structural (hourly) maximum, maximum and minimum for the PSD). ####
ZZZ_bound <- data.frame(Year = c(2018:2020),
PSD_min = c(40.16, 42.35, 39.68),
PSD_max = c(505.18, 513.89, 559.75),
PSD_max_struc = c(NA,NA,1148.36),
stringsAsFactors = F)
#### Files (download via CCEE's website) are on relative paths. ####
# They are treated under the "tidyverse" package and "tidy data philosophy/methodology"
# Worth mentioning that the manual date '2018-09-08' sets the largest period
# of Hourly PSD time series without 'errors and omissions' of CCEE database.
# Luckly, it stars on a saturday, which is essential for the ID_Week "over partition by" calculation
# to get ID_Week on the Hourly PSD dataframe.
ZZZ_Weekly_PSD <- bind_rows(... =
lapply(list.files('PSD/',full.names = T),function(x){
readxl::read_excel(x,trim_ws = T) %>%
rename(Year_Weekly = Ano, Month_Weekly = Mês, Week = Semana,
Start_Date = `Data Início`,
End_Date = `Data Fim`) %>%
mutate(Start_Date = ymd(Start_Date),End_Date = ymd(End_Date)) %>%
gather(data =.,key='SubMkt_LoadStep',value='PSD',-(Year_Weekly:End_Date)) %>%
separate(SubMkt_LoadStep, c("LoadStep","SubMkt"), sep = " ") %>%
mutate(SubMkt = factor(SubMkt,labels=c('NE','SE','S','N'),levels=c('NE','SE','S','N')),
#Ordered factor.
LoadStep = factor(LoadStep,ordered=T,levels=c('Leve','Médio','Pesado')),
PSD = as.numeric(PSD))
})
) %>% arrange(Start_Date)
ZZZ_Hourly_PSD <- bind_rows(... =
lapply(list.files('PSDh/',full.names = T),function(x){
readxl::read_excel(x,trim_ws = T) %>% rename(Hour_Hourly = `...1`,SubMkt=`...2`) %>%
filter(Hour_Hourly != 'Hora') %>% gather(data =.,key='Date',value='PSDh',-Hour_Hourly,-SubMkt) %>%
filter(!is.na(PSDh)) %>%
mutate(PSDh = as.numeric(PSDh),SubMkt = as.factor(SubMkt),
Hour_Hourly=as.numeric(Hour_Hourly),
Date = as.Date(as.numeric(Date),origin='1899-12-30'),
SubMkt = case_when(
toupper(SubMkt) == 'SUDESTE' ~ 'SE',
toupper(SubMkt) == 'NORTE' ~ 'N',
toupper(SubMkt) == 'SUL' ~ 'S',
toupper(SubMkt) == 'NORDESTE' ~ 'NE',
T ~ 'Erro'),
SubMkt = factor(SubMkt,labels=c('NE','SE','S','N'),levels=c('NE','SE','S','N'))
) %>%
mutate(Key = as.POSIXct(strptime(paste0(Date,' 00:00'),"%Y-%m-%d %H:%M"),tz = "America/Buenos_Aires") + (Hour_Hourly*1*60*60))
})
) %>% #filter(Date >= ymd('2018-10-01')) %>%
arrange(Date,Hour_Hourly)
if(ZZZ_Hourly_PSD %>% group_by(Date,Hour_Hourly,SubMkt) %>% filter(n()!=1) %>% nrow() != 0){
print('Number of rows different from expected quantity of hours!')
}else{}
# Commented piece: calculates time interval between two dates.
# T_length <- time_length(
#   interval(
#     min(ZZZ_Hourly_PSD$Date),
#     max(ZZZ_Hourly_PSD$Date)
#   ),"day")
# Commented piece: equally lengthed partition; time-vector.
# vec.tempo.teste <- lubridate::ymd(min(ZZZ_Hourly_PSD$Date)) %m+% days(0:763)
# After the proper data cleaning of the Weekly and Hourly PSD's,
# the argument of fnc.VLookUp_Weekly_vs_Hourly(df_Days_PSDh) is settled.
#### LoadSteps per hours, season and type: bind_rows through years. ####
ZZZ_LoadSteps <- bind_rows(... =
lapply(list.files('Other_Data/',pattern = 'LoadStep_*',full.names = T),
function(x){
x <- readxl::read_excel(x,trim_ws = T)
colnames(x) <- str_to_upper(colnames(x))
return(x %>% mutate_all(as.character))
})) %>%
mutate(Date = as.Date(DIA,origin='1899-12-30'), Hour_LoadStep = str_sub(HORA,-8,-4),
Week_LoadStep = str_sub(SEMANA,-1,-1),
WeekDay_LoadStep = `DIA SEMANA`,  Type_LoadStep = TIPO) %>%
mutate(DayLightType = str_to_lower(`TIPO HORÁRIO`)) %>%
mutate(DayLightType = if_else(is.na(DayLightType),'horário normal',DayLightType)) %>%
mutate(LoadStep = PATAMAR) %>%
mutate(LoadStep = case_when(
str_to_upper(LoadStep) == 'LEVE' ~ 'Leve',
str_to_upper(LoadStep) == 'MÉDIO' ~ 'Médio',
str_to_upper(LoadStep) == 'PESADO' ~ 'Pesado',
T ~ 'Erro'
)) %>%  mutate(LoadStep = factor(LoadStep,ordered=T,levels=c('Leve','Médio','Pesado'))) %>%
dplyr::select((Date:LoadStep)) %>%
#Strictly necessary: there is an unexplicable behavior under 'America/Sao_Paulo' time zone.
mutate(Key = as.POSIXct(strptime(paste0(Date,' ',Hour_LoadStep),"%Y-%m-%d %H:%M"),tz = "America/Buenos_Aires"))
# Test to verify which month is lacking days on a Hourly PSD basis.
# View(
#   ZZZ_Hourly_PSD %>% select(Date) %>%
#     mutate(`Year/Month` = paste0(str_sub(Date,1,4),'/',str_sub(Date,6,7))) %>% distinct() %>%
#     mutate(fnc_Days = days_in_month(Date)) %>%
#     group_by(fnc_Days,`Year/Month`) %>% mutate(Days_in_Month = n()) %>%
#     ungroup() %>% filter(Days_in_Month != fnc_Days)
#   )
#
source('Sub/function_dataframe_PSD.R')
dataframe_PSD <- fnc.dataframe_PSD(
ZZZ_Hourly_PSD=ZZZ_Hourly_PSD,
ZZZ_Weekly_PSD=ZZZ_Weekly_PSD,
ZZZ_LoadSteps=ZZZ_LoadSteps,
ZZZ_VLookUp_Holidays=ZZZ_VLookUp_Holidays
)
writexl::write_xlsx(x = dataframe_PSD,'../Stochastic_Processes_PSD_Output/dataframe_PSD.xlsx')
vMinDate <- min(ZZZ_Hourly_PSD$Date)
vMaxDate <- max(ZZZ_Hourly_PSD$Date)
vRefWDay <- wday(ymd(vMaxDate),week_start = 6)
vRefEndDate <- min(ymd(ZZZ_Weekly_PSD$End_Date))
# Criteria to filter the starting weekly prices on End_Date vs. vMinDate
df_W_PSD <- ZZZ_Weekly_PSD %>% filter(End_Date >= vMinDate) %>%
group_by(SubMkt, LoadStep) %>% mutate(ID_Week = row_number()) %>% ungroup()
vec.Start_Date <- unique(df_W_PSD$Start_Date)
df_H_PSD <- ZZZ_Hourly_PSD %>% mutate(ID_Week = 0)
for(RefDate in vec.Start_Date){
df_H_PSD <- mutate(.data = df_H_PSD,ID_Week = if_else(Date >= RefDate,ID_Week+1,ID_Week))
}
df <- df_H_PSD %>%
left_join(ZZZ_LoadSteps, by=c('Key'='Key','Date'='Date')) %>%
left_join(df_W_PSD,by=c('ID_Week'='ID_Week','SubMkt'='SubMkt','LoadStep'='LoadStep')) %>%
mutate(Year = str_sub(Date,1,4)) %>%
rename(timestamp = Key) %>% mutate(`Year/Month` = paste0(Year,'/',str_sub(Date,6,7))) %>%
mutate(`Year/Month/Day` = paste0(`Year/Month`,'/',day(Date)))
df <- df %>%
mutate(Month = lubridate::month(Date)) %>%
mutate(Month_label = lubridate::month(Date,label=T,abbr=T)) %>%
mutate(CurrWDay = wday(Date,label=T,abbr=T,week_start = 6)) %>%
mutate(WeekDay_LoadStep = case_when(
str_to_lower(WeekDay_LoadStep) == 'segunda-feira' ~ 'seg',
str_to_lower(WeekDay_LoadStep) == 'terça-feira' ~ 'ter',
str_to_lower(WeekDay_LoadStep) == 'quarta-feira' ~ 'qua',
str_to_lower(WeekDay_LoadStep) == 'quinta-feira' ~ 'qui',
str_to_lower(WeekDay_LoadStep) == 'sexta-feira' ~ 'sex',
str_to_lower(WeekDay_LoadStep) == 'feriado' ~ 'fer',
str_to_lower(WeekDay_LoadStep) == 'sábado' ~ 'sáb',
str_to_lower(WeekDay_LoadStep) == 'domingo' ~ 'dom',
)) %>%
mutate(WeekDay_LoadStep = factor(WeekDay_LoadStep,ordered =F,levels=c('sáb','dom','fer','seg','ter','qua','qui','sex'))) %>%
#Current WeekDay (without holiday classification).
mutate(CurrWDay = wday(Date,label=T,abbr=T,week_start = 6)) %>%
#Adjustment on the current week days: holiday classification comes from ZZZ_VLookUp_Holidays.
mutate(WDay = if_else(Date %in% ZZZ_VLookUp_Holidays$Date,'fer',as.character(CurrWDay))) %>%
#Factor variable is NOT ordered!
mutate(WDay = factor(WDay,ordered =F,levels=c('sáb','dom','fer','seg','ter','qua','qui','sex'))) %>%
#Season, order factor by month. #Firstly, 2019 and after the end of the Daylight Saving Time.
#Then, there is a further classification of 2018 and 2019 up to 2019-02-06 for the DS Time.
mutate(Season = case_when(
#Summer
((Month >= 1 & Month <= 3)) ~ 'Verão - T1',
#Intermediate
((Month == 4)) ~ 'Intra-Estac. - Abr',
#Winter
Month >= 5 & Month <= 8 ~ 'Inverno',
#Intermediate
((Month >= 9 & Month <= 10)) ~ 'Intra-Estac. - Set/Out',
#Summer
((Month >= 11 & Month <= 12)) ~ 'Verão - T4',
T ~ 'Erro')) %>%
mutate(Season = case_when(
Date >= ymd('2018-01-01') & Date <= ymd('2018-02-17') ~ 'Daylight Saving Time',
Date >= ymd('2018-02-18') & Date <= ymd('2018-11-03') ~ 'Normal Time',
Date >= ymd('2018-11-04') & Date <= ymd('2018-02-16') ~ 'Daylight Saving Time',
T ~'Erro')) %>%
#   Season = factor(Season,ordered=T,levels = c(
#     'Verão - T1','Intra-Estac. - Abr',
#     'Inverno','Intra-Estac. - Set/Out',
#     'Verão - T4')
#   )
# )
mutate(log_diff = log(PSDh/PSD),diff_perc = (PSDh/PSD)-1,diff_nom = (PSDh-PSD)) %>%
dplyr::select(SubMkt,Date,`Year/Month`,`Year/Month/Day`,Hour_LoadStep,WeekDay_LoadStep,WDay,LoadStep,
PSD,PSDh,log_diff,diff_perc,diff_nom,everything())
View(dataframe_PSD)
View(df)
vMinDate <- min(ZZZ_Hourly_PSD$Date)
vMaxDate <- max(ZZZ_Hourly_PSD$Date)
vRefWDay <- wday(ymd(vMaxDate),week_start = 6)
vRefEndDate <- min(ymd(ZZZ_Weekly_PSD$End_Date))
# Criteria to filter the starting weekly prices on End_Date vs. vMinDate
df_W_PSD <- ZZZ_Weekly_PSD %>% filter(End_Date >= vMinDate) %>%
group_by(SubMkt, LoadStep) %>% mutate(ID_Week = row_number()) %>% ungroup()
vec.Start_Date <- unique(df_W_PSD$Start_Date)
df_H_PSD <- ZZZ_Hourly_PSD %>% mutate(ID_Week = 0)
for(RefDate in vec.Start_Date){
df_H_PSD <- mutate(.data = df_H_PSD,ID_Week = if_else(Date >= RefDate,ID_Week+1,ID_Week))
}
df <- df_H_PSD %>%
left_join(ZZZ_LoadSteps, by=c('Key'='Key','Date'='Date')) %>%
left_join(df_W_PSD,by=c('ID_Week'='ID_Week','SubMkt'='SubMkt','LoadStep'='LoadStep')) %>%
mutate(Year = str_sub(Date,1,4)) %>%
rename(timestamp = Key) %>% mutate(`Year/Month` = paste0(Year,'/',str_sub(Date,6,7))) %>%
mutate(`Year/Month/Day` = paste0(`Year/Month`,'/',day(Date)))
df <- df %>%
mutate(Month = lubridate::month(Date)) %>%
mutate(Month_label = lubridate::month(Date,label=T,abbr=T)) %>%
mutate(CurrWDay = wday(Date,label=T,abbr=T,week_start = 6)) %>%
mutate(WeekDay_LoadStep = case_when(
str_to_lower(WeekDay_LoadStep) == 'segunda-feira' ~ 'seg',
str_to_lower(WeekDay_LoadStep) == 'terça-feira' ~ 'ter',
str_to_lower(WeekDay_LoadStep) == 'quarta-feira' ~ 'qua',
str_to_lower(WeekDay_LoadStep) == 'quinta-feira' ~ 'qui',
str_to_lower(WeekDay_LoadStep) == 'sexta-feira' ~ 'sex',
str_to_lower(WeekDay_LoadStep) == 'feriado' ~ 'fer',
str_to_lower(WeekDay_LoadStep) == 'sábado' ~ 'sáb',
str_to_lower(WeekDay_LoadStep) == 'domingo' ~ 'dom',
)) %>%
mutate(WeekDay_LoadStep = factor(WeekDay_LoadStep,ordered =F,levels=c('sáb','dom','fer','seg','ter','qua','qui','sex'))) %>%
#Current WeekDay (without holiday classification).
mutate(CurrWDay = wday(Date,label=T,abbr=T,week_start = 6)) %>%
#Adjustment on the current week days: holiday classification comes from ZZZ_VLookUp_Holidays.
mutate(WDay = if_else(Date %in% ZZZ_VLookUp_Holidays$Date,'fer',as.character(CurrWDay))) %>%
#Factor variable is NOT ordered!
mutate(WDay = factor(WDay,ordered =F,levels=c('sáb','dom','fer','seg','ter','qua','qui','sex'))) %>%
#Season, order factor by month. #Firstly, 2019 and after the end of the Daylight Saving Time.
#Then, there is a further classification of 2018 and 2019 up to 2019-02-06 for the DS Time.
mutate(Season = case_when(
#Summer
((Month >= 1 & Month <= 3)) ~ 'Verão - T1',
#Intermediate
((Month == 4)) ~ 'Intra-Estac. - Abr',
#Winter
Month >= 5 & Month <= 8 ~ 'Inverno',
#Intermediate
((Month >= 9 & Month <= 10)) ~ 'Intra-Estac. - Set/Out',
#Summer
((Month >= 11 & Month <= 12)) ~ 'Verão - T4',
T ~ 'Erro')) %>%
mutate(Season = case_when(
Date >= ymd('2018-01-01') & Date <= ymd('2018-02-17') ~ 'Daylight Saving Time',
Date >= ymd('2018-02-18') & Date <= ymd('2018-11-03') ~ 'Normal Time',
Date >= ymd('2019-11-04') & Date <= ymd('2019-02-16') ~ 'Daylight Saving Time',
T ~'Erro')) %>%
#   Season = factor(Season,ordered=T,levels = c(
#     'Verão - T1','Intra-Estac. - Abr',
#     'Inverno','Intra-Estac. - Set/Out',
#     'Verão - T4')
#   )
# )
mutate(log_diff = log(PSDh/PSD),diff_perc = (PSDh/PSD)-1,diff_nom = (PSDh-PSD)) %>%
dplyr::select(SubMkt,Date,`Year/Month`,`Year/Month/Day`,Hour_LoadStep,WeekDay_LoadStep,WDay,LoadStep,
PSD,PSDh,log_diff,diff_perc,diff_nom,everything())
View(df)
Date >= ymd('2018-01-01') & Date <= ymd('2018-02-17') ~ 'Daylight Saving Time',
Date >= ymd('2018-02-18') & Date <= ymd('2018-11-03') ~ 'Normal Time',
Date >= ymd('2018-11-04') & Date <= ymd('2019-02-16') ~ 'Daylight Saving Time',
T ~ Season)) %>%
#   Season = factor(Season,ordered=T,levels = c(
#     'Verão - T1','Intra-Estac. - Abr',
#     'Inverno','Intra-Estac. - Set/Out',
#     'Verão - T4')
#   )
# )
mutate(log_diff = log(PSDh/PSD),diff_perc = (PSDh/PSD)-1,diff_nom = (PSDh-PSD)) %>%
dplyr::select(SubMkt,Date,`Year/Month`,`Year/Month/Day`,Hour_LoadStep,WeekDay_LoadStep,WDay,LoadStep,
PSD,PSDh,log_diff,diff_perc,diff_nom,everything())
vMinDate <- min(ZZZ_Hourly_PSD$Date)
vMaxDate <- max(ZZZ_Hourly_PSD$Date)
vRefWDay <- wday(ymd(vMaxDate),week_start = 6)
vRefEndDate <- min(ymd(ZZZ_Weekly_PSD$End_Date))
# Criteria to filter the starting weekly prices on End_Date vs. vMinDate
df_W_PSD <- ZZZ_Weekly_PSD %>% filter(End_Date >= vMinDate) %>%
group_by(SubMkt, LoadStep) %>% mutate(ID_Week = row_number()) %>% ungroup()
vec.Start_Date <- unique(df_W_PSD$Start_Date)
df_H_PSD <- ZZZ_Hourly_PSD %>% mutate(ID_Week = 0)
for(RefDate in vec.Start_Date){
df_H_PSD <- mutate(.data = df_H_PSD,ID_Week = if_else(Date >= RefDate,ID_Week+1,ID_Week))
}
df <- df_H_PSD %>%
left_join(ZZZ_LoadSteps, by=c('Key'='Key','Date'='Date')) %>%
left_join(df_W_PSD,by=c('ID_Week'='ID_Week','SubMkt'='SubMkt','LoadStep'='LoadStep')) %>%
mutate(Year = str_sub(Date,1,4)) %>%
rename(timestamp = Key) %>% mutate(`Year/Month` = paste0(Year,'/',str_sub(Date,6,7))) %>%
mutate(`Year/Month/Day` = paste0(`Year/Month`,'/',day(Date)))
df <- df %>%
mutate(Month = lubridate::month(Date)) %>%
mutate(Month_label = lubridate::month(Date,label=T,abbr=T)) %>%
mutate(CurrWDay = wday(Date,label=T,abbr=T,week_start = 6)) %>%
mutate(WeekDay_LoadStep = case_when(
str_to_lower(WeekDay_LoadStep) == 'segunda-feira' ~ 'seg',
str_to_lower(WeekDay_LoadStep) == 'terça-feira' ~ 'ter',
str_to_lower(WeekDay_LoadStep) == 'quarta-feira' ~ 'qua',
str_to_lower(WeekDay_LoadStep) == 'quinta-feira' ~ 'qui',
str_to_lower(WeekDay_LoadStep) == 'sexta-feira' ~ 'sex',
str_to_lower(WeekDay_LoadStep) == 'feriado' ~ 'fer',
str_to_lower(WeekDay_LoadStep) == 'sábado' ~ 'sáb',
str_to_lower(WeekDay_LoadStep) == 'domingo' ~ 'dom',
)) %>%
mutate(WeekDay_LoadStep = factor(WeekDay_LoadStep,ordered =F,levels=c('sáb','dom','fer','seg','ter','qua','qui','sex'))) %>%
#Current WeekDay (without holiday classification).
mutate(CurrWDay = wday(Date,label=T,abbr=T,week_start = 6)) %>%
#Adjustment on the current week days: holiday classification comes from ZZZ_VLookUp_Holidays.
mutate(WDay = if_else(Date %in% ZZZ_VLookUp_Holidays$Date,'fer',as.character(CurrWDay))) %>%
#Factor variable is NOT ordered!
mutate(WDay = factor(WDay,ordered =F,levels=c('sáb','dom','fer','seg','ter','qua','qui','sex'))) %>%
#Season, order factor by month. #Firstly, 2019 and after the end of the Daylight Saving Time.
#Then, there is a further classification of 2018 and 2019 up to 2019-02-06 for the DS Time.
mutate(Season = case_when(
#Summer
((Month >= 1 & Month <= 3)) ~ 'Verão - T1',
#Intermediate
((Month == 4)) ~ 'Intra-Estac. - Abr',
#Winter
Month >= 5 & Month <= 8 ~ 'Inverno',
#Intermediate
((Month >= 9 & Month <= 10)) ~ 'Intra-Estac. - Set/Out',
#Summer
((Month >= 11 & Month <= 12)) ~ 'Verão - T4',
T ~ 'Erro')) %>%
mutate(Season = case_when(
Date >= ymd('2018-01-01') & Date <= ymd('2018-02-17') ~ 'Daylight Saving Time',
Date >= ymd('2018-02-18') & Date <= ymd('2018-11-03') ~ 'Normal Time',
Date >= ymd('2018-11-04') & Date <= ymd('2019-02-16') ~ 'Daylight Saving Time',
T ~ Season)) %>%
#   Season = factor(Season,ordered=T,levels = c(
#     'Verão - T1','Intra-Estac. - Abr',
#     'Inverno','Intra-Estac. - Set/Out',
#     'Verão - T4')
#   )
# )
mutate(log_diff = log(PSDh/PSD),diff_perc = (PSDh/PSD)-1,diff_nom = (PSDh-PSD)) %>%
dplyr::select(SubMkt,Date,`Year/Month`,`Year/Month/Day`,Hour_LoadStep,WeekDay_LoadStep,WDay,LoadStep,
PSD,PSDh,log_diff,diff_perc,diff_nom,everything())
return(df)
fnc.dataframe_PSD <- function(ZZZ_Hourly_PSD,ZZZ_Weekly_PSD,ZZZ_LoadSteps,ZZZ_VLookUp_Holidays){
vMinDate <- min(ZZZ_Hourly_PSD$Date)
vMaxDate <- max(ZZZ_Hourly_PSD$Date)
vRefWDay <- wday(ymd(vMaxDate),week_start = 6)
vRefEndDate <- min(ymd(ZZZ_Weekly_PSD$End_Date))
# Criteria to filter the starting weekly prices on End_Date vs. vMinDate
df_W_PSD <- ZZZ_Weekly_PSD %>% filter(End_Date >= vMinDate) %>%
group_by(SubMkt, LoadStep) %>% mutate(ID_Week = row_number()) %>% ungroup()
vec.Start_Date <- unique(df_W_PSD$Start_Date)
df_H_PSD <- ZZZ_Hourly_PSD %>% mutate(ID_Week = 0)
for(RefDate in vec.Start_Date){
df_H_PSD <- mutate(.data = df_H_PSD,ID_Week = if_else(Date >= RefDate,ID_Week+1,ID_Week))
}
df <- df_H_PSD %>%
left_join(ZZZ_LoadSteps, by=c('Key'='Key','Date'='Date')) %>%
left_join(df_W_PSD,by=c('ID_Week'='ID_Week','SubMkt'='SubMkt','LoadStep'='LoadStep')) %>%
mutate(Year = str_sub(Date,1,4)) %>%
rename(timestamp = Key) %>% mutate(`Year/Month` = paste0(Year,'/',str_sub(Date,6,7))) %>%
mutate(`Year/Month/Day` = paste0(`Year/Month`,'/',day(Date)))
df <- df %>%
mutate(Month = lubridate::month(Date)) %>%
mutate(Month_label = lubridate::month(Date,label=T,abbr=T)) %>%
mutate(CurrWDay = wday(Date,label=T,abbr=T,week_start = 6)) %>%
mutate(WeekDay_LoadStep = case_when(
str_to_lower(WeekDay_LoadStep) == 'segunda-feira' ~ 'seg',
str_to_lower(WeekDay_LoadStep) == 'terça-feira' ~ 'ter',
str_to_lower(WeekDay_LoadStep) == 'quarta-feira' ~ 'qua',
str_to_lower(WeekDay_LoadStep) == 'quinta-feira' ~ 'qui',
str_to_lower(WeekDay_LoadStep) == 'sexta-feira' ~ 'sex',
str_to_lower(WeekDay_LoadStep) == 'feriado' ~ 'fer',
str_to_lower(WeekDay_LoadStep) == 'sábado' ~ 'sáb',
str_to_lower(WeekDay_LoadStep) == 'domingo' ~ 'dom',
)) %>%
mutate(WeekDay_LoadStep = factor(WeekDay_LoadStep,ordered =F,levels=c('sáb','dom','fer','seg','ter','qua','qui','sex'))) %>%
#Current WeekDay (without holiday classification).
mutate(CurrWDay = wday(Date,label=T,abbr=T,week_start = 6)) %>%
#Adjustment on the current week days: holiday classification comes from ZZZ_VLookUp_Holidays.
mutate(WDay = if_else(Date %in% ZZZ_VLookUp_Holidays$Date,'fer',as.character(CurrWDay))) %>%
#Factor variable is NOT ordered!
mutate(WDay = factor(WDay,ordered =F,levels=c('sáb','dom','fer','seg','ter','qua','qui','sex'))) %>%
#Season, order factor by month. #Firstly, 2019 and after the end of the Daylight Saving Time.
#Then, there is a further classification of 2018 and 2019 up to 2019-02-06 for the DS Time.
mutate(Season = case_when(
#Summer
((Month >= 1 & Month <= 3)) ~ 'Verão - T1',
#Intermediate
((Month == 4)) ~ 'Intra-Estac. - Abr',
#Winter
Month >= 5 & Month <= 8 ~ 'Inverno',
#Intermediate
((Month >= 9 & Month <= 10)) ~ 'Intra-Estac. - Set/Out',
#Summer
((Month >= 11 & Month <= 12)) ~ 'Verão - T4',
T ~ 'Erro')) %>%
mutate(Season = case_when(
Date >= ymd('2018-01-01') & Date <= ymd('2018-02-17') ~ 'Daylight Saving Time',
Date >= ymd('2018-02-18') & Date <= ymd('2018-11-03') ~ 'Normal Time',
Date >= ymd('2018-11-04') & Date <= ymd('2019-02-16') ~ 'Daylight Saving Time',
T ~ Season)) %>%
#   Season = factor(Season,ordered=T,levels = c(
#     'Verão - T1','Intra-Estac. - Abr',
#     'Inverno','Intra-Estac. - Set/Out',
#     'Verão - T4')
#   )
# )
mutate(log_diff = log(PSDh/PSD),diff_perc = (PSDh/PSD)-1,diff_nom = (PSDh-PSD)) %>%
dplyr::select(SubMkt,Date,`Year/Month`,`Year/Month/Day`,Hour_LoadStep,WeekDay_LoadStep,WDay,LoadStep,
PSD,PSDh,log_diff,diff_perc,diff_nom,everything())
return(df)
}
source('C:/Users/dataprev/Dropbox/000_Monografia/Stochastic_Processes_PSD/000_xls_to_rds.R', echo=TRUE)
df_teste <- dataframe_PSD %>% filter(SubMkt == 'SE') %>%
filter(LoadStep == 'Pesado')
cols <- c("Leve" = 'green', "Médio" = "orange", "Pesado" = "#E41A1C")
dataframe_PSD %>% ggplot(data =., aes(x = log_diff)) +
scale_colour_manual(values = cols) +
facet_grid(rows=vars(SubMkt),cols=vars(Year),scales = "free")  + theme_bw() +
# Set legend position of SubMkt
theme(legend.position="bottom", legend.title = element_blank())
dataframe_PSD %>% ggplot(data =., aes(x = log_diff)) +
geom_histogram() +
scale_colour_manual(values = cols) +
facet_grid(rows=vars(SubMkt),cols=vars(Year),scales = "free",margins = 'Year')  + theme_bw() +
# Set legend position of SubMkt
theme(legend.position="bottom", legend.title = element_blank())
dataframe_PSD %>% ggplot(data =., aes(x = log_diff, fill = LoadStep)) +
geom_histogram() +
scale_colour_manual(values = cols) +
facet_grid(rows=vars(SubMkt),cols=vars(Year),scales = "free",margins = 'Year')  + theme_bw() +
# Set legend position of SubMkt
theme(legend.position="bottom", legend.title = element_blank())
dataframe_PSD %>% ggplot(data =., aes(x = log_diff, fill = LoadStep)) +
geom_histogram() +
scale_fill_manual(values = cols) +
facet_grid(rows=vars(SubMkt),cols=vars(Year),scales = "free",margins = 'Year')  + theme_bw() +
# Set legend position of SubMkt
theme(legend.position="bottom", legend.title = element_blank())
dataframe_PSD %>% ggplot(data =., aes(x = log_diff, fill = LoadStep)) +
geom_histogram(aes(y=..density..)) +
scale_fill_manual(values = cols) +
facet_grid(rows=vars(SubMkt),cols=vars(Year),scales = "free",margins = 'Year')  + theme_bw() +
# Set legend position of SubMkt
theme(legend.position="bottom", legend.title = element_blank())
dataframe_PSD %>% ggplot(data =., aes(x = log_diff, fill = LoadStep)) +
geom_histogram(aes(y=..density..)) +
scale_fill_manual(values = cols) +
facet_grid(rows=vars(SubMkt,LoadStep),cols=vars(Year),scales = "free",margins = 'Year')  + theme_bw() +
# Set legend position of SubMkt
theme(legend.position="bottom", legend.title = element_blank())
dataframe_PSD %>% ggplot(data =., aes(x = log_diff, colour = LoadStep)) +
geom_histogram(aes(y=..density..),position="identity", alpha=0.5) +
scale_colour_manual(values = cols) +
facet_grid(rows=vars(SubMkt),cols=vars(Year),scales = "free",margins = 'Year')  + theme_bw() +
# Set legend position of SubMkt
theme(legend.position="bottom", legend.title = element_blank())
dataframe_PSD %>% ggplot(data =., aes(x = log_diff, fill = 'white', colour = LoadStep)) +
geom_histogram(aes(y=..density..),position="identity", alpha=0.5) +
scale_colour_manual(values = cols) +
facet_grid(rows=vars(SubMkt),cols=vars(Year),scales = "free",margins = 'Year')  + theme_bw() +
# Set legend position of SubMkt
theme(legend.position="bottom", legend.title = element_blank())
dataframe_PSD %>% ggplot(data =., aes(x = log_diff, colour = LoadStep)) +
geom_histogram(aes(y=..density..),fill = 'white',position="identity", alpha=0.5) +
scale_colour_manual(values = cols) +
facet_grid(rows=vars(SubMkt),cols=vars(Year),scales = "free",margins = 'Year')  + theme_bw() +
# Set legend position of SubMkt
theme(legend.position="bottom", legend.title = element_blank())
dataframe_PSD %>% ggplot(data =., aes(x = log_diff, colour = LoadStep)) +
geom_histogram(aes(y=..density..),fill = 'white',position="identity", alpha=0.5) +
scale_colour_manual(values = cols) +
facet_grid(rows=vars(SubMkt),cols=vars(Year),scales = "free",margins = 'Year')  + theme_bw() +
# Set legend position of SubMkt
theme(legend.position="bottom", legend.title = element_blank())
dataframe_PSD %>% ggplot(data =., aes(x = log_diff, colour = LoadStep)) +
geom_freqpoly(aes(y=..density..),fill = 'white',position="identity", alpha=0.5) +
scale_colour_manual(values = cols) +
facet_grid(rows=vars(SubMkt),cols=vars(Year),scales = "free",margins = 'Year')  + theme_bw() +
# Set legend position of SubMkt
theme(legend.position="bottom", legend.title = element_blank())
dataframe_PSD %>% ggplot(data =., aes(x = log_diff, colour = LoadStep)) +
geom_density(aes(y=..density..),fill = 'white',position="identity", alpha=0.5) +
scale_colour_manual(values = cols) +
facet_grid(rows=vars(SubMkt),cols=vars(Year),scales = "free",margins = 'Year')  + theme_bw() +
# Set legend position of SubMkt
theme(legend.position="bottom", legend.title = element_blank())
dataframe_PSD %>% ggplot(data =., aes(x = log_diff, colour = LoadStep)) +
geom_density(aes(y=..density..), alpha=0.5) +
scale_colour_manual(values = cols) +
facet_grid(rows=vars(SubMkt),cols=vars(Year),scales = "free",margins = 'Year')  + theme_bw() +
# Set legend position of SubMkt
theme(legend.position="bottom", legend.title = element_blank())
dataframe_PSD %>% ggplot(data =., aes(x = log_diff, colour = LoadStep)) +
geom_histogram(aes(y=..density..), alpha=0.5) +
scale_colour_manual(values = cols) +
facet_grid(rows=vars(SubMkt),cols=vars(Year),scales = "free",margins = 'Year')  + theme_bw() +
# Set legend position of SubMkt
theme(legend.position="bottom", legend.title = element_blank())  +
xlab(TeX(paste0('log \\left(\\frac{PLDh_{t}}{PLD_{w,t}} \\right)'))) +
ylab(label = element_blank())
vec.pkg <- c("latex2exp",'MASS',"rstudioapi","lubridate","tidyverse","tictoc",'readxl')
vec.newpkg <- vec.pkg[!(vec.pkg %in% installed.packages()[,"Package"])]
if(length(vec.newpkg)) install.packages(vec.newpkg)
lapply(vec.pkg, require, character.only = TRUE)
rm(vec.pkg,vec.newpkg)
